# FINAL PROJECT – Multiple Document Format Reconciler

## Project Overview

In my company, we receive multiple files reporting the commission amounts our sales team has earned. These reports arrive in different formats (TXT, CSV, PDF) and with varying periodicity. Furthermore, the files contain different data columns and organization, as they are generated by different lenders.

Currently, I spend significant time manually reviewing each column, adjusting for the relevant timeframe, and calculating our total production.

An AI-powered web application that can review all documents and reconcile the information into a standard format would save a great deal of time and significantly improve our workflow.

---

## Use Case & Workflow

The primary goal is to speed up and automate my reconciliation workload. Our business is a lending company that partners with multiple banks. However, this solution could benefit any business receiving reports in different formats and at different intervals, helping them consolidate data into a single source of truth.

---

## AI Features to Be Implemented

### Prompt Engineering

An enhanced prompt will be used to identify columns across different lender-specific formats. Since files are somewhat consistent, there is an expectation of what columns to expect.

AI will be used for:

* **Intelligent column mapping** for lender-specific formats.
* **Data normalization** (e.g., standardizing date formats and currency values).
* **Date matching** to align sales dates with commission periods.
* **Duplicate detection** for previously imported entries.

### Few-Shot Prompting

To improve accuracy, example mappings will be included in prompts so the LLM can align to a clear source of truth. This is important given that financial terminology can be ambiguous. Guardrails will be put in place to handle potential inconsistencies.

### Structured Outputs

Commission data must be parsed into predictable fields:

* `date` (datetime)
* `product_name` (string)
* `gross_commission` (float)
* `net_commission` (float)
* `lender_name` (string)

These will be displayed on a webpage for easy review.

---

## Evaluation Frameworks

* **Tracing** – For logging each processing step.
* **A/B testing prompts** – To determine if different examples improve accuracy.
* **Chaining** – The process involves sequential steps: detect lender → parse → normalize → deduplicate → save to DB → update UI. Chaining ensures each step runs in order and passes structured data forward.
* **Human in the Loop** – For new lender formats, low-confidence mappings, or ambiguous dates, the system should request manual confirmation.

---

## Technical Approach

**AI Components**

* OpenAI LLM for document review and data extraction.
* Pinecone for vectorization (approximating column name definitions).

**Frontend**

* Next.js app hosted on Vercel.
* Dashboard for viewing commissions by date range and tracking imported files.

**Backend**

* Node.js API for handling file uploads and Gmail ingestion via MCP integration.
* AI processing with OpenAI GPT-4o (or similar) for parsing and mapping.
* File parsing libraries for CSV/TXT, and `pdfplumber` for read-only PDFs.

**Database**

* PostgreSQL (Supabase) for storing normalized commission records and import metadata.
* Vector database (Pinecone or pgvector) for storing column mapping embeddings.

**Automation**

* Gmail webhook triggers ingestion when new files arrive.
* Manual uploads available via the dashboard.
* Role-based access control for security.

---

## Example Prompts & Expected Outputs

**Prompt**

```
You are an AI file parser. The following file contains commission report data from a lender.  
Your task is to identify relevant columns and output a JSON array following this schema:  
[ { sale_date, contract_id, customer_id, gross_commission, net_commission, lender_name } ]  

If you cannot confidently map a column, output "unknown" for that field and request clarification.
```

**Expected Output**

```json
{
  "date": "2025-07-12",
  "product_name": "personal credit",
  "gross_commission": 500.00,
  "net_commission": 450.00,
  "lender_name": "Banco X"
}
```

---

## Evaluation Strategy

* **String comparison** – Verify if the parsed output matches expected values, especially given the repetitive nature of the task.
* **Guardrails** – As I am the sole end user and authentication is in place, extensive guardrails are not necessary.

---

## Observability Plan

Performance monitoring is a lower priority since the application will run once a day and handle a straightforward process.

Error handling will primarily be manual, with logs available for diagnosing failures or parsing issues.
